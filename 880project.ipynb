{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date                                               text ticker signal\n",
      "0  2015-01-02  success apple pay part determined lies hands p...   AAPL   down\n",
      "1  2015-01-05        time take note lies top fashion agenda 2015   AAPL   down\n",
      "2  2015-01-08  google app store largest world still makes far...   AAPL     up\n",
      "3  2015-01-09  facebook eventually reverts top stories view n...   AAPL     up\n",
      "4  2015-01-14  planned bill would expand new york definition ...   AAPL   down\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('BIG_DATA.txt')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Model (a majority of this code is copied from the BERT Tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date                                               text ticker signal\n",
      "0  2015-01-02  success apple pay part determined lies hands p...   AAPL   down\n",
      "1  2015-01-05        time take note lies top fashion agenda 2015   AAPL   down\n",
      "2  2015-01-08  google app store largest world still makes far...   AAPL     up\n",
      "3  2015-01-09  facebook eventually reverts top stories view n...   AAPL     up\n",
      "4  2015-01-14  planned bill would expand new york definition ...   AAPL   down\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df = pd.read_csv('texts_and_fin2.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n",
      "88\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "# Run this cell for a function for oversampling\n",
    "\n",
    "def oversample(X,y):\n",
    "    # Get number of rows with imbalanced class\n",
    "    target = y.sum().idxmax()\n",
    "    n = y[target].sum()\n",
    "    # identify imbalanced targets\n",
    "    imbalanced = y.drop(target,axis=1)\n",
    "    #For each target, create a dataframe of randomly sampled rows, append to list\n",
    "    append_list =  [y.loc[y[col]==1].sample(n=n-y[col].sum(),replace=True,random_state=20) for col in imbalanced.columns]\n",
    "    append_list.append(y)\n",
    "    y = pd.concat(append_list,axis=0)\n",
    "    # match y indexes on other inputs\n",
    "    X = X.loc[y.index]\n",
    "    assert (y.index.all() == X.index.all())\n",
    "    return X, y\n",
    "\n",
    "df = df.rename(columns = {\"text\": \"filtered_text\"})\n",
    "df = df.sort_values(by='Date', ascending=True, axis=0)\n",
    "testNum = int(len(df) * -.1)\n",
    "X_train = df['filtered_text'][:testNum].dropna()\n",
    "y_train = pd.get_dummies(columns=['signal'],data=df['signal'])[:testNum].dropna().iloc[:, :]\n",
    "test = df.loc[list(set(list(df.index)) - set(list(X_train.index)))]\n",
    "X_test = test['filtered_text'].dropna()\n",
    "y_test = test['signal'].dropna()\n",
    "\n",
    "X_train, y_train = oversample(X_train, y_train)\n",
    "# print(len(y_train['stay']))\n",
    "# print(len(y_train['down']))\n",
    "# print(len(y_train['up']))\n",
    "\n",
    "# Recreate the signal variable\n",
    "y_train[\"signal\"] = np.nan\n",
    "\n",
    "# for i, y in y_train.iterrows():\n",
    "#     if str(type(y_train.loc[i])) == \"<class 'pandas.core.frame.DataFrame'>\": # If an index only has one observation, it draws up an error if we try to use the indexer agaon\n",
    "#         # They're usually classed as a series while the ones with many observations are considered a df. This is a way to get\n",
    "#         # rid of them\n",
    "#         if y_train.loc[i].iloc[0, 0] == 1:\n",
    "#             y_train.loc[i, \"signal\"] = \"down\"\n",
    "#         elif y_train.loc[i].iloc[0, 1] == 1:\n",
    "#             y_train.loc[i, \"signal\"] = \"stay\"\n",
    "#         else:\n",
    "#             y_train.loc[i, \"signal\"] = \"up\"\n",
    "#     else: # If they only have one observation, we settle it here instead\n",
    "#         if y_train.loc[i][0] == 1:\n",
    "#               y_train.loc[i, \"signal\"] = \"down\"\n",
    "#         elif y_train.loc[i][1] == 1:\n",
    "#             y_train.loc[i, \"signal\"] = \"stay\"\n",
    "#         else:\n",
    "#             y_train.loc[i, \"signal\"] = \"up\"\n",
    "            \n",
    "X_train2 = X_train.reset_index(drop = True)\n",
    "y_train2 = y_train['signal'].reset_index(drop = True)\n",
    "\n",
    "data = pd.concat([X_train2, y_train2], axis = 1)\n",
    "data.rename(columns = {\"filtered_text\":\"doc\"}, inplace = True)\n",
    "\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "train = data\n",
    "test = pd.concat([X_test, y_test], axis = 1) \n",
    "test.rename(columns = {\"filtered_text\":\"doc\"}, inplace = True)\n",
    "print(test.signal.str.count('stay').sum())\n",
    "print(test.signal.str.count('up').sum())\n",
    "print(test.signal.str.count('down').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:23.839895 4711937472 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.281285 4711937472 run_classifier.py:774] Writing example 0 of 681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.289957 4711937472 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.291429 4711937472 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] twitter t ##wt ##r suffers today apple aa ##pl party ##ing stock tops price tag , penny ##stock research uh ##al tr ##v ch ##k aa ##pl wealth ##mana ##gement , option millionaire ##s jimmy ##bo ##b aa ##pl pm , aa ##pl everyone continues estimate basically telling us continue buy long ##fr ##om cc , samsung in ##fr ##inge first stall long possible strategies nothing new day aa ##pl , swing trading approach free ##s watching markets live web ##ina ##r sunday aa ##pl goo ##g , ali ##ba ##ba compares major tech companies aa ##pl goo ##g ms ##ft , ha ##r considering investing cm ##i cbs ##h aa ##pl view , aa ##pl stock target achieved gain sell med ##elli ##n aa ##pl [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.292907 4711937472 run_classifier.py:464] tokens: [CLS] twitter t ##wt ##r suffers today apple aa ##pl party ##ing stock tops price tag , penny ##stock research uh ##al tr ##v ch ##k aa ##pl wealth ##mana ##gement , option millionaire ##s jimmy ##bo ##b aa ##pl pm , aa ##pl everyone continues estimate basically telling us continue buy long ##fr ##om cc , samsung in ##fr ##inge first stall long possible strategies nothing new day aa ##pl , swing trading approach free ##s watching markets live web ##ina ##r sunday aa ##pl goo ##g , ali ##ba ##ba compares major tech companies aa ##pl goo ##g ms ##ft , ha ##r considering investing cm ##i cbs ##h aa ##pl view , aa ##pl stock target achieved gain sell med ##elli ##n aa ##pl [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 10474 1056 26677 2099 17567 2651 6207 9779 24759 2283 2075 4518 13284 3976 6415 1010 10647 14758 2470 7910 2389 19817 2615 10381 2243 9779 24759 7177 24805 20511 1010 5724 19965 2015 5261 5092 2497 9779 24759 7610 1010 9779 24759 3071 4247 10197 10468 4129 2149 3613 4965 2146 19699 5358 10507 1010 19102 1999 19699 23496 2034 13498 2146 2825 9942 2498 2047 2154 9779 24759 1010 7370 6202 3921 2489 2015 3666 6089 2444 4773 3981 2099 4465 9779 24759 27571 2290 1010 4862 3676 3676 22963 2350 6627 3316 9779 24759 27571 2290 5796 6199 1010 5292 2099 6195 19920 4642 2072 6568 2232 9779 24759 3193 1010 9779 24759 4518 4539 4719 5114 5271 19960 13348 2078 9779 24759 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.294041 4711937472 run_classifier.py:465] input_ids: 101 10474 1056 26677 2099 17567 2651 6207 9779 24759 2283 2075 4518 13284 3976 6415 1010 10647 14758 2470 7910 2389 19817 2615 10381 2243 9779 24759 7177 24805 20511 1010 5724 19965 2015 5261 5092 2497 9779 24759 7610 1010 9779 24759 3071 4247 10197 10468 4129 2149 3613 4965 2146 19699 5358 10507 1010 19102 1999 19699 23496 2034 13498 2146 2825 9942 2498 2047 2154 9779 24759 1010 7370 6202 3921 2489 2015 3666 6089 2444 4773 3981 2099 4465 9779 24759 27571 2290 1010 4862 3676 3676 22963 2350 6627 3316 9779 24759 27571 2290 5796 6199 1010 5292 2099 6195 19920 4642 2072 6568 2232 9779 24759 3193 1010 9779 24759 4518 4539 4719 5114 5271 19960 13348 2078 9779 24759 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.295430 4711937472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.296856 4711937472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: down (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.298305 4711937472 run_classifier.py:468] label: down (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.308400 4711937472 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.309595 4711937472 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] monday market outlook aa ##pl trades since june ideas bt ##u ch ##k y ##ho ##o db ##a ho ##v ir ##bt h , monday market outlook aa ##pl trades since june ideas bt ##u ch ##k y ##ho ##o db ##a ho ##v ir ##bt h , monday market outlook aa ##pl trades since june ideas bt ##u ch ##k y ##ho ##o db ##a ho ##v ir ##bt h , aa ##pl gt ##at , week left sign online wealth management co ##use w ucla ##ex ##tension investing spy baba aa ##pl , apple technical ##s monthly weekly daily fi ##bon ##ac ##ci levels update aa ##pl u ##b u ##b u ##b aa ##pl , aa ##pl apple record setting launch analysts predict [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.310711 4711937472 run_classifier.py:464] tokens: [CLS] monday market outlook aa ##pl trades since june ideas bt ##u ch ##k y ##ho ##o db ##a ho ##v ir ##bt h , monday market outlook aa ##pl trades since june ideas bt ##u ch ##k y ##ho ##o db ##a ho ##v ir ##bt h , monday market outlook aa ##pl trades since june ideas bt ##u ch ##k y ##ho ##o db ##a ho ##v ir ##bt h , aa ##pl gt ##at , week left sign online wealth management co ##use w ucla ##ex ##tension investing spy baba aa ##pl , apple technical ##s monthly weekly daily fi ##bon ##ac ##ci levels update aa ##pl u ##b u ##b u ##b aa ##pl , aa ##pl apple record setting launch analysts predict [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 6928 3006 17680 9779 24759 14279 2144 2238 4784 18411 2226 10381 2243 1061 6806 2080 16962 2050 7570 2615 20868 19279 1044 1010 6928 3006 17680 9779 24759 14279 2144 2238 4784 18411 2226 10381 2243 1061 6806 2080 16962 2050 7570 2615 20868 19279 1044 1010 6928 3006 17680 9779 24759 14279 2144 2238 4784 18411 2226 10381 2243 1061 6806 2080 16962 2050 7570 2615 20868 19279 1044 1010 9779 24759 14181 4017 1010 2733 2187 3696 3784 7177 2968 2522 8557 1059 12389 10288 29048 19920 8645 14208 9779 24759 1010 6207 4087 2015 7058 4882 3679 10882 11735 6305 6895 3798 10651 9779 24759 1057 2497 1057 2497 1057 2497 9779 24759 1010 9779 24759 6207 2501 4292 4888 18288 16014 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.312602 4711937472 run_classifier.py:465] input_ids: 101 6928 3006 17680 9779 24759 14279 2144 2238 4784 18411 2226 10381 2243 1061 6806 2080 16962 2050 7570 2615 20868 19279 1044 1010 6928 3006 17680 9779 24759 14279 2144 2238 4784 18411 2226 10381 2243 1061 6806 2080 16962 2050 7570 2615 20868 19279 1044 1010 6928 3006 17680 9779 24759 14279 2144 2238 4784 18411 2226 10381 2243 1061 6806 2080 16962 2050 7570 2615 20868 19279 1044 1010 9779 24759 14181 4017 1010 2733 2187 3696 3784 7177 2968 2522 8557 1059 12389 10288 29048 19920 8645 14208 9779 24759 1010 6207 4087 2015 7058 4882 3679 10882 11735 6305 6895 3798 10651 9779 24759 1057 2497 1057 2497 1057 2497 9779 24759 1010 9779 24759 6207 2501 4292 4888 18288 16014 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.314202 4711937472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.315379 4711937472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: down (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.317071 4711937472 run_classifier.py:468] label: down (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.322412 4711937472 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.323896 4711937472 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] topping popping market true value ts ##la y ##ho ##o pc ##ln nfl ##x aa ##pl q ##q ##q it ##m ##n investing , make vega friend lesson portfolio management spy ru ##t es _ f aa ##pl , topping popping market true value ts ##la y ##ho ##o pc ##ln nfl ##x aa ##pl q ##q ##q it ##m ##n investing , aa ##pl companies get involved politics stock stocks stock ##act ##ion , aa ##pl sprint mv ##no ting add support iphone usage based plans next mac , apple issued security fix mac ##s install software update yet aa ##pl , new galaxy ##s fails impress mw ##c ss ##nl ##f s ##ne aa ##pl l ##ng ##vy , topping popping market true value [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.325591 4711937472 run_classifier.py:464] tokens: [CLS] topping popping market true value ts ##la y ##ho ##o pc ##ln nfl ##x aa ##pl q ##q ##q it ##m ##n investing , make vega friend lesson portfolio management spy ru ##t es _ f aa ##pl , topping popping market true value ts ##la y ##ho ##o pc ##ln nfl ##x aa ##pl q ##q ##q it ##m ##n investing , aa ##pl companies get involved politics stock stocks stock ##act ##ion , aa ##pl sprint mv ##no ting add support iphone usage based plans next mac , apple issued security fix mac ##s install software update yet aa ##pl , new galaxy ##s fails impress mw ##c ss ##nl ##f s ##ne aa ##pl l ##ng ##vy , topping popping market true value [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 22286 20095 3006 2995 3643 24529 2721 1061 6806 2080 7473 19666 5088 2595 9779 24759 1053 4160 4160 2009 2213 2078 19920 1010 2191 15942 2767 10800 11103 2968 8645 21766 2102 9686 1035 1042 9779 24759 1010 22286 20095 3006 2995 3643 24529 2721 1061 6806 2080 7473 19666 5088 2595 9779 24759 1053 4160 4160 2009 2213 2078 19920 1010 9779 24759 3316 2131 2920 4331 4518 15768 4518 18908 3258 1010 9779 24759 9043 19842 3630 28642 5587 2490 18059 8192 2241 3488 2279 6097 1010 6207 3843 3036 8081 6097 2015 16500 4007 10651 2664 9779 24759 1010 2047 9088 2015 11896 17894 12464 2278 7020 20554 2546 1055 2638 9779 24759 1048 3070 10736 1010 22286 20095 3006 2995 3643 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.326750 4711937472 run_classifier.py:465] input_ids: 101 22286 20095 3006 2995 3643 24529 2721 1061 6806 2080 7473 19666 5088 2595 9779 24759 1053 4160 4160 2009 2213 2078 19920 1010 2191 15942 2767 10800 11103 2968 8645 21766 2102 9686 1035 1042 9779 24759 1010 22286 20095 3006 2995 3643 24529 2721 1061 6806 2080 7473 19666 5088 2595 9779 24759 1053 4160 4160 2009 2213 2078 19920 1010 9779 24759 3316 2131 2920 4331 4518 15768 4518 18908 3258 1010 9779 24759 9043 19842 3630 28642 5587 2490 18059 8192 2241 3488 2279 6097 1010 6207 3843 3036 8081 6097 2015 16500 4007 10651 2664 9779 24759 1010 2047 9088 2015 11896 17894 12464 2278 7020 20554 2546 1055 2638 9779 24759 1048 3070 10736 1010 22286 20095 3006 2995 3643 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.327840 4711937472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.329153 4711937472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: down (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.330133 4711937472 run_classifier.py:468] label: down (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.337411 4711937472 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.338414 4711937472 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] aa ##pl long ##s yesterday green thanks ibm news changed sl protect profit , aa ##pl bull ##ish alert d ##ma d ##ma d ##ma d ##ma d ##ma price , apple buy tesla really ts ##la aa ##pl , aa ##pl je ##ez would today without announcement want op ##ex , apple ibm announce landmark deal develop apps aa ##pl tech stocks , fly hours move ##rs aa ##pl tech stocks , stocks watch n ##v ##gt f ##n ##ma fm ##cc new ##l mine aa ##pl goo ##g q ##q ##q , trade year aa ##pl already ibm ba ##c i ##w ##m t ##f _ f options ##tra ##te ##gies beth ##eh ##ouse picks http , apple ibm kill blackberry bb ##ry stock [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.339321 4711937472 run_classifier.py:464] tokens: [CLS] aa ##pl long ##s yesterday green thanks ibm news changed sl protect profit , aa ##pl bull ##ish alert d ##ma d ##ma d ##ma d ##ma d ##ma price , apple buy tesla really ts ##la aa ##pl , aa ##pl je ##ez would today without announcement want op ##ex , apple ibm announce landmark deal develop apps aa ##pl tech stocks , fly hours move ##rs aa ##pl tech stocks , stocks watch n ##v ##gt f ##n ##ma fm ##cc new ##l mine aa ##pl goo ##g q ##q ##q , trade year aa ##pl already ibm ba ##c i ##w ##m t ##f _ f options ##tra ##te ##gies beth ##eh ##ouse picks http , apple ibm kill blackberry bb ##ry stock [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 9779 24759 2146 2015 7483 2665 4283 9980 2739 2904 22889 4047 5618 1010 9779 24759 7087 4509 9499 1040 2863 1040 2863 1040 2863 1040 2863 1040 2863 3976 1010 6207 4965 26060 2428 24529 2721 9779 24759 1010 9779 24759 15333 9351 2052 2651 2302 8874 2215 6728 10288 1010 6207 9980 14970 8637 3066 4503 18726 9779 24759 6627 15768 1010 4875 2847 2693 2869 9779 24759 6627 15768 1010 15768 3422 1050 2615 13512 1042 2078 2863 4718 9468 2047 2140 3067 9779 24759 27571 2290 1053 4160 4160 1010 3119 2095 9779 24759 2525 9980 8670 2278 1045 2860 2213 1056 2546 1035 1042 7047 6494 2618 17252 7014 11106 15441 11214 8299 1010 6207 9980 3102 25935 22861 2854 4518 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.340430 4711937472 run_classifier.py:465] input_ids: 101 9779 24759 2146 2015 7483 2665 4283 9980 2739 2904 22889 4047 5618 1010 9779 24759 7087 4509 9499 1040 2863 1040 2863 1040 2863 1040 2863 1040 2863 3976 1010 6207 4965 26060 2428 24529 2721 9779 24759 1010 9779 24759 15333 9351 2052 2651 2302 8874 2215 6728 10288 1010 6207 9980 14970 8637 3066 4503 18726 9779 24759 6627 15768 1010 4875 2847 2693 2869 9779 24759 6627 15768 1010 15768 3422 1050 2615 13512 1042 2078 2863 4718 9468 2047 2140 3067 9779 24759 27571 2290 1053 4160 4160 1010 3119 2095 9779 24759 2525 9980 8670 2278 1045 2860 2213 1056 2546 1035 1042 7047 6494 2618 17252 7014 11106 15441 11214 8299 1010 6207 9980 3102 25935 22861 2854 4518 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.341858 4711937472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.344012 4711937472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: down (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.344806 4711937472 run_classifier.py:468] label: down (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.354522 4711937472 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.355381 4711937472 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] aa ##pl holding oct u g mac ##book pro quad core w yuan dev ##al ##uation components get cheaper china labor cheaper , p stocks performance hal cat aa ##pl ap ##c ox ##y d ##vn hp ##q cop sl ##b int ##c met cv ##x t ##w ##x dow x ##om , goo ##g aa ##pl t ##wt ##r monday market rec ##ap update option millionaire ##s stock options chat ##room today rally cam , aa ##pl ax ##p baba cv ##x f ##b mon r ##l x ##om see ya tomorrow bless day watching baba earning morning , aa ##pl trade alert , may paying much higher spreads us tech giants aa ##pl goo ##gl ms ##ft f ##b t ##wt ##r spread ##bet [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.356569 4711937472 run_classifier.py:464] tokens: [CLS] aa ##pl holding oct u g mac ##book pro quad core w yuan dev ##al ##uation components get cheaper china labor cheaper , p stocks performance hal cat aa ##pl ap ##c ox ##y d ##vn hp ##q cop sl ##b int ##c met cv ##x t ##w ##x dow x ##om , goo ##g aa ##pl t ##wt ##r monday market rec ##ap update option millionaire ##s stock options chat ##room today rally cam , aa ##pl ax ##p baba cv ##x f ##b mon r ##l x ##om see ya tomorrow bless day watching baba earning morning , aa ##pl trade alert , may paying much higher spreads us tech giants aa ##pl goo ##gl ms ##ft f ##b t ##wt ##r spread ##bet [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 9779 24759 3173 13323 1057 1043 6097 8654 4013 17718 4563 1059 11237 16475 2389 14505 6177 2131 16269 2859 4450 16269 1010 1052 15768 2836 11085 4937 9779 24759 9706 2278 23060 2100 1040 16022 6522 4160 8872 22889 2497 20014 2278 2777 26226 2595 1056 2860 2595 23268 1060 5358 1010 27571 2290 9779 24759 1056 26677 2099 6928 3006 28667 9331 10651 5724 19965 2015 4518 7047 11834 9954 2651 8320 11503 1010 9779 24759 22260 2361 14208 26226 2595 1042 2497 12256 1054 2140 1060 5358 2156 8038 4826 19994 2154 3666 14208 7414 2851 1010 9779 24759 3119 9499 1010 2089 7079 2172 3020 20861 2149 6627 7230 9779 24759 27571 23296 5796 6199 1042 2497 1056 26677 2099 3659 20915 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.358036 4711937472 run_classifier.py:465] input_ids: 101 9779 24759 3173 13323 1057 1043 6097 8654 4013 17718 4563 1059 11237 16475 2389 14505 6177 2131 16269 2859 4450 16269 1010 1052 15768 2836 11085 4937 9779 24759 9706 2278 23060 2100 1040 16022 6522 4160 8872 22889 2497 20014 2278 2777 26226 2595 1056 2860 2595 23268 1060 5358 1010 27571 2290 9779 24759 1056 26677 2099 6928 3006 28667 9331 10651 5724 19965 2015 4518 7047 11834 9954 2651 8320 11503 1010 9779 24759 22260 2361 14208 26226 2595 1042 2497 12256 1054 2140 1060 5358 2156 8038 4826 19994 2154 3666 14208 7414 2851 1010 9779 24759 3119 9499 1010 2089 7079 2172 3020 20861 2149 6627 7230 9779 24759 27571 23296 5796 6199 1042 2497 1056 26677 2099 3659 20915 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.359343 4711937472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.360352 4711937472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: down (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:24.361540 4711937472 run_classifier.py:468] label: down (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.118936 4711937472 run_classifier.py:774] Writing example 0 of 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.132787 4711937472 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.133950 4711937472 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] sen ##al twitter en aa ##pl , aa ##pl ts ##la freaking awesome day chat options money times nailed good roll raining ##mon ##ey , brandon clay interviewed options ##tra ##te ##gies portfolio ##mana ##gement macro ##en ##vir ##on ##ment ibm aa ##pl http , brandon clay interviewed options ##tra ##te ##gies portfolio ##mana ##gement macro ##en ##vir ##on ##ment ibm aa ##pl http , beat people trading aa ##pl ranking , brandon clay interviewed options ##tra ##te ##gies portfolio ##mana ##gement macro ##en ##vir ##on ##ment ibm aa ##pl http , brandon clay interviewed options ##tra ##te ##gies portfolio ##mana ##gement macro ##en ##vir ##on ##ment ibm aa ##pl http , aa ##pl keep eye closes could first successful close months would v bull ##ish [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.135430 4711937472 run_classifier.py:464] tokens: [CLS] sen ##al twitter en aa ##pl , aa ##pl ts ##la freaking awesome day chat options money times nailed good roll raining ##mon ##ey , brandon clay interviewed options ##tra ##te ##gies portfolio ##mana ##gement macro ##en ##vir ##on ##ment ibm aa ##pl http , brandon clay interviewed options ##tra ##te ##gies portfolio ##mana ##gement macro ##en ##vir ##on ##ment ibm aa ##pl http , beat people trading aa ##pl ranking , brandon clay interviewed options ##tra ##te ##gies portfolio ##mana ##gement macro ##en ##vir ##on ##ment ibm aa ##pl http , brandon clay interviewed options ##tra ##te ##gies portfolio ##mana ##gement macro ##en ##vir ##on ##ment ibm aa ##pl http , aa ##pl keep eye closes could first successful close months would v bull ##ish [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 12411 2389 10474 4372 9779 24759 1010 9779 24759 24529 2721 13847 12476 2154 11834 7047 2769 2335 26304 2204 4897 24057 8202 3240 1010 8825 5726 10263 7047 6494 2618 17252 11103 24805 20511 26632 2368 21663 2239 3672 9980 9779 24759 8299 1010 8825 5726 10263 7047 6494 2618 17252 11103 24805 20511 26632 2368 21663 2239 3672 9980 9779 24759 8299 1010 3786 2111 6202 9779 24759 5464 1010 8825 5726 10263 7047 6494 2618 17252 11103 24805 20511 26632 2368 21663 2239 3672 9980 9779 24759 8299 1010 8825 5726 10263 7047 6494 2618 17252 11103 24805 20511 26632 2368 21663 2239 3672 9980 9779 24759 8299 1010 9779 24759 2562 3239 14572 2071 2034 3144 2485 2706 2052 1058 7087 4509 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.136502 4711937472 run_classifier.py:465] input_ids: 101 12411 2389 10474 4372 9779 24759 1010 9779 24759 24529 2721 13847 12476 2154 11834 7047 2769 2335 26304 2204 4897 24057 8202 3240 1010 8825 5726 10263 7047 6494 2618 17252 11103 24805 20511 26632 2368 21663 2239 3672 9980 9779 24759 8299 1010 8825 5726 10263 7047 6494 2618 17252 11103 24805 20511 26632 2368 21663 2239 3672 9980 9779 24759 8299 1010 3786 2111 6202 9779 24759 5464 1010 8825 5726 10263 7047 6494 2618 17252 11103 24805 20511 26632 2368 21663 2239 3672 9980 9779 24759 8299 1010 8825 5726 10263 7047 6494 2618 17252 11103 24805 20511 26632 2368 21663 2239 3672 9980 9779 24759 8299 1010 9779 24759 2562 3239 14572 2071 2034 3144 2485 2706 2052 1058 7087 4509 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.138009 4711937472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.139785 4711937472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: up (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.140797 4711937472 run_classifier.py:468] label: up (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.148363 4711937472 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.149269 4711937472 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] different news tab ##s open aa ##pl db bp give , breaking hut ##ham ol ##ayan elected ibm board directors aa ##pl ts ##la goo ##gl , breaking ex thomas cook boss green lands top ibm role aa ##pl ts ##la goo ##gl , top ##tick ##ert ##wee ##ts vr ##x spy aa ##pl t ##wt ##r w ##t ##w fin ##tech fins ##er ##v , q ##q ##q h ##ft al ##gos triggered buy sigma x cross ##finder at ##s l ##x p quan ##t ms ##ft f ##b gp ##ro am ##z ##n goo ##g aa ##pl ts ##la nfl ##x , aa ##pl apple inc day high aa ##pl jp ##m b ##lc ##m pv ##g aa ##pl stocks finance , pp ##g [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.150125 4711937472 run_classifier.py:464] tokens: [CLS] different news tab ##s open aa ##pl db bp give , breaking hut ##ham ol ##ayan elected ibm board directors aa ##pl ts ##la goo ##gl , breaking ex thomas cook boss green lands top ibm role aa ##pl ts ##la goo ##gl , top ##tick ##ert ##wee ##ts vr ##x spy aa ##pl t ##wt ##r w ##t ##w fin ##tech fins ##er ##v , q ##q ##q h ##ft al ##gos triggered buy sigma x cross ##finder at ##s l ##x p quan ##t ms ##ft f ##b gp ##ro am ##z ##n goo ##g aa ##pl ts ##la nfl ##x , aa ##pl apple inc day high aa ##pl jp ##m b ##lc ##m pv ##g aa ##pl stocks finance , pp ##g [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2367 2739 21628 2015 2330 9779 24759 16962 17531 2507 1010 4911 12570 3511 19330 25868 2700 9980 2604 5501 9779 24759 24529 2721 27571 23296 1010 4911 4654 2726 5660 5795 2665 4915 2327 9980 2535 9779 24759 24529 2721 27571 23296 1010 2327 26348 8743 28394 3215 27830 2595 8645 9779 24759 1056 26677 2099 1059 2102 2860 10346 15007 18564 2121 2615 1010 1053 4160 4160 1044 6199 2632 12333 13330 4965 13201 1060 2892 23695 2012 2015 1048 2595 1052 24110 2102 5796 6199 1042 2497 14246 3217 2572 2480 2078 27571 2290 9779 24759 24529 2721 5088 2595 1010 9779 24759 6207 4297 2154 2152 9779 24759 16545 2213 1038 15472 2213 26189 2290 9779 24759 15768 5446 1010 4903 2290 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.151264 4711937472 run_classifier.py:465] input_ids: 101 2367 2739 21628 2015 2330 9779 24759 16962 17531 2507 1010 4911 12570 3511 19330 25868 2700 9980 2604 5501 9779 24759 24529 2721 27571 23296 1010 4911 4654 2726 5660 5795 2665 4915 2327 9980 2535 9779 24759 24529 2721 27571 23296 1010 2327 26348 8743 28394 3215 27830 2595 8645 9779 24759 1056 26677 2099 1059 2102 2860 10346 15007 18564 2121 2615 1010 1053 4160 4160 1044 6199 2632 12333 13330 4965 13201 1060 2892 23695 2012 2015 1048 2595 1052 24110 2102 5796 6199 1042 2497 14246 3217 2572 2480 2078 27571 2290 9779 24759 24529 2721 5088 2595 1010 9779 24759 6207 4297 2154 2152 9779 24759 16545 2213 1038 15472 2213 26189 2290 9779 24759 15768 5446 1010 4903 2290 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.153387 4711937472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.154762 4711937472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: stay (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.155626 4711937472 run_classifier.py:468] label: stay (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.160637 4711937472 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.161594 4711937472 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] ahead us tech giants check analyst say goo ##g t ##wt ##r aa ##pl , today earnings could create market cap milestone ##s am ##z ##n b ms ##ft b goo ##gl b joining aa ##pl , aa ##pl sell luca mae ##st ##ri senior vice pre ##s cf ##o , aa ##pl , aa ##pl iphone sales could di ##sa ##point ##ing , em ##br rolling ##gg ##gg ##g get ##tt em ##mm cm ##go va ##pe am ##zz td ##ey pv ##sp sip ##c tb ##ev nr ##ti ac ##ol aa ##pl goo ##gl l ##ken spy g ##ds ##i ur ##bf , real audio video luxury luxury ##life ##sty ##le nyc shopping aa ##pl , cong ##rat ##s bulls months taking bottom paid [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.162992 4711937472 run_classifier.py:464] tokens: [CLS] ahead us tech giants check analyst say goo ##g t ##wt ##r aa ##pl , today earnings could create market cap milestone ##s am ##z ##n b ms ##ft b goo ##gl b joining aa ##pl , aa ##pl sell luca mae ##st ##ri senior vice pre ##s cf ##o , aa ##pl , aa ##pl iphone sales could di ##sa ##point ##ing , em ##br rolling ##gg ##gg ##g get ##tt em ##mm cm ##go va ##pe am ##zz td ##ey pv ##sp sip ##c tb ##ev nr ##ti ac ##ol aa ##pl goo ##gl l ##ken spy g ##ds ##i ur ##bf , real audio video luxury luxury ##life ##sty ##le nyc shopping aa ##pl , cong ##rat ##s bulls months taking bottom paid [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 3805 2149 6627 7230 4638 12941 2360 27571 2290 1056 26677 2099 9779 24759 1010 2651 16565 2071 3443 3006 6178 19199 2015 2572 2480 2078 1038 5796 6199 1038 27571 23296 1038 5241 9779 24759 1010 9779 24759 5271 15604 11530 3367 3089 3026 3580 3653 2015 12935 2080 1010 9779 24759 1010 9779 24759 18059 4341 2071 4487 3736 8400 2075 1010 7861 19892 5291 13871 13871 2290 2131 4779 7861 7382 4642 3995 12436 5051 2572 13213 14595 3240 26189 13102 10668 2278 26419 6777 17212 3775 9353 4747 9779 24759 27571 23296 1048 7520 8645 1043 5104 2072 24471 29292 1010 2613 5746 2678 9542 9542 15509 21756 2571 16392 6023 9779 24759 1010 26478 8609 2015 12065 2706 2635 3953 3825 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.164615 4711937472 run_classifier.py:465] input_ids: 101 3805 2149 6627 7230 4638 12941 2360 27571 2290 1056 26677 2099 9779 24759 1010 2651 16565 2071 3443 3006 6178 19199 2015 2572 2480 2078 1038 5796 6199 1038 27571 23296 1038 5241 9779 24759 1010 9779 24759 5271 15604 11530 3367 3089 3026 3580 3653 2015 12935 2080 1010 9779 24759 1010 9779 24759 18059 4341 2071 4487 3736 8400 2075 1010 7861 19892 5291 13871 13871 2290 2131 4779 7861 7382 4642 3995 12436 5051 2572 13213 14595 3240 26189 13102 10668 2278 26419 6777 17212 3775 9353 4747 9779 24759 27571 23296 1048 7520 8645 1043 5104 2072 24471 29292 1010 2613 5746 2678 9542 9542 15509 21756 2571 16392 6023 9779 24759 1010 26478 8609 2015 12065 2706 2635 3953 3825 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.166037 4711937472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.167016 4711937472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: up (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.168149 4711937472 run_classifier.py:468] label: up (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.175327 4711937472 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.176578 4711937472 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] assets seeing jump t ##wee ##ts aa ##pl am ##z ##n dj ##ia eu ##rus ##d goo ##gl , aa ##pl report apple music near release android app , wi ##x smart new source revenue stocks trading investing f ##b aa ##pl , apple new million annual revenue stream growing aa ##pl , watch week ahead monday oct aa ##pl , simple apple strategy right even simpler aa ##pl strategy buy hold aaa ##aa ##aa ##and scene , dust dire ##xi ##on daily gold miners bear x shares w ##k high dust aa ##pl fx ##e jo dust nas ##da ##q nas ##da ##q , beat people trading aa ##pl ranking holy shit trading game , china drops rates amazon drops profit markets go wild aa [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.178428 4711937472 run_classifier.py:464] tokens: [CLS] assets seeing jump t ##wee ##ts aa ##pl am ##z ##n dj ##ia eu ##rus ##d goo ##gl , aa ##pl report apple music near release android app , wi ##x smart new source revenue stocks trading investing f ##b aa ##pl , apple new million annual revenue stream growing aa ##pl , watch week ahead monday oct aa ##pl , simple apple strategy right even simpler aa ##pl strategy buy hold aaa ##aa ##aa ##and scene , dust dire ##xi ##on daily gold miners bear x shares w ##k high dust aa ##pl fx ##e jo dust nas ##da ##q nas ##da ##q , beat people trading aa ##pl ranking holy shit trading game , china drops rates amazon drops profit markets go wild aa [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 7045 3773 5376 1056 28394 3215 9779 24759 2572 2480 2078 6520 2401 7327 7946 2094 27571 23296 1010 9779 24759 3189 6207 2189 2379 2713 11924 10439 1010 15536 2595 6047 2047 3120 6599 15768 6202 19920 1042 2497 9779 24759 1010 6207 2047 2454 3296 6599 5460 3652 9779 24759 1010 3422 2733 3805 6928 13323 9779 24759 1010 3722 6207 5656 2157 2130 16325 9779 24759 5656 4965 2907 13360 11057 11057 5685 3496 1010 6497 18704 9048 2239 3679 2751 11257 4562 1060 6661 1059 2243 2152 6497 9779 24759 23292 2063 8183 6497 17235 2850 4160 17235 2850 4160 1010 3786 2111 6202 9779 24759 5464 4151 4485 6202 2208 1010 2859 9010 6165 9733 9010 5618 6089 2175 3748 9779 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.179703 4711937472 run_classifier.py:465] input_ids: 101 7045 3773 5376 1056 28394 3215 9779 24759 2572 2480 2078 6520 2401 7327 7946 2094 27571 23296 1010 9779 24759 3189 6207 2189 2379 2713 11924 10439 1010 15536 2595 6047 2047 3120 6599 15768 6202 19920 1042 2497 9779 24759 1010 6207 2047 2454 3296 6599 5460 3652 9779 24759 1010 3422 2733 3805 6928 13323 9779 24759 1010 3722 6207 5656 2157 2130 16325 9779 24759 5656 4965 2907 13360 11057 11057 5685 3496 1010 6497 18704 9048 2239 3679 2751 11257 4562 1060 6661 1059 2243 2152 6497 9779 24759 23292 2063 8183 6497 17235 2850 4160 17235 2850 4160 1010 3786 2111 6202 9779 24759 5464 4151 4485 6202 2208 1010 2859 9010 6165 9733 9010 5618 6089 2175 3748 9779 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.181546 4711937472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.182678 4711937472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: up (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.183552 4711937472 run_classifier.py:468] label: up (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.192659 4711937472 run_classifier.py:461] *** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.194155 4711937472 run_classifier.py:462] guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] aa ##pl apple inc filing ##s aa ##pl i ##w ##m dia pg aa ##pl invest finance , apple refusing unlock iphone us law enforcement aa ##pl , am ##d looks promising aa ##pl ms ##ft , top ##tick ##ert ##wee ##ts vr ##x aa ##pl spy b ##ds ##i t ##wt ##r fin ##tech fins ##er ##v , gil ##d q aa ##pl q earnings market close tomorrow two heavy weights respective industries , the ##st ##ree ##t apple tv future tv tim cook rocker aa ##pl , video traders always use stops dj ##ia spy es _ f n ##q _ f q ##q ##q v ##xx u ##wt ##i aa ##pl , sky ##car _ jack sal ##uting great nor ##cal tech co [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.195372 4711937472 run_classifier.py:464] tokens: [CLS] aa ##pl apple inc filing ##s aa ##pl i ##w ##m dia pg aa ##pl invest finance , apple refusing unlock iphone us law enforcement aa ##pl , am ##d looks promising aa ##pl ms ##ft , top ##tick ##ert ##wee ##ts vr ##x aa ##pl spy b ##ds ##i t ##wt ##r fin ##tech fins ##er ##v , gil ##d q aa ##pl q earnings market close tomorrow two heavy weights respective industries , the ##st ##ree ##t apple tv future tv tim cook rocker aa ##pl , video traders always use stops dj ##ia spy es _ f n ##q _ f q ##q ##q v ##xx u ##wt ##i aa ##pl , sky ##car _ jack sal ##uting great nor ##cal tech co [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 9779 24759 6207 4297 15242 2015 9779 24759 1045 2860 2213 22939 18720 9779 24759 15697 5446 1010 6207 11193 19829 18059 2149 2375 7285 9779 24759 1010 2572 2094 3504 10015 9779 24759 5796 6199 1010 2327 26348 8743 28394 3215 27830 2595 9779 24759 8645 1038 5104 2072 1056 26677 2099 10346 15007 18564 2121 2615 1010 13097 2094 1053 9779 24759 1053 16565 3006 2485 4826 2048 3082 15871 7972 6088 1010 1996 3367 9910 2102 6207 2694 2925 2694 5199 5660 24779 9779 24759 1010 2678 13066 2467 2224 6762 6520 2401 8645 9686 1035 1042 1050 4160 1035 1042 1053 4160 4160 1058 20348 1057 26677 2072 9779 24759 1010 3712 10010 1035 2990 16183 20807 2307 4496 9289 6627 2522 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.196349 4711937472 run_classifier.py:465] input_ids: 101 9779 24759 6207 4297 15242 2015 9779 24759 1045 2860 2213 22939 18720 9779 24759 15697 5446 1010 6207 11193 19829 18059 2149 2375 7285 9779 24759 1010 2572 2094 3504 10015 9779 24759 5796 6199 1010 2327 26348 8743 28394 3215 27830 2595 9779 24759 8645 1038 5104 2072 1056 26677 2099 10346 15007 18564 2121 2615 1010 13097 2094 1053 9779 24759 1053 16565 3006 2485 4826 2048 3082 15871 7972 6088 1010 1996 3367 9910 2102 6207 2694 2925 2694 5199 5660 24779 9779 24759 1010 2678 13066 2467 2224 6762 6520 2401 8645 9686 1035 1042 1050 4160 1035 1042 1053 4160 4160 1058 20348 1057 26677 2072 9779 24759 1010 3712 10010 1035 2990 16183 20807 2307 4496 9289 6627 2522 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.197562 4711937472 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.198927 4711937472 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: down (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:33:28.200636 4711937472 run_classifier.py:468] label: down (id = 1)\n"
     ]
    }
   ],
   "source": [
    "DATA_COLUMN = 'doc'\n",
    "LABEL_COLUMN = 'signal'\n",
    "# label_list is the list of labels\n",
    "label_list = ['up', 'down', 'stay']\n",
    "\n",
    "\n",
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()\n",
    "\n",
    "# We'll set sequences to be at most 128 tokens long.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  # \"\"\"Creates a classification model.\"\"\"\n",
    "    bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "    bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "    # Create our own layer to tune for politeness data.\n",
    "    output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)\n",
    "\n",
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "    # \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "      #   \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "        # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "            (loss, predicted_labels, log_probs) = create_model(\n",
    "                is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            train_op = bert.optimization.create_optimizer(\n",
    "              loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "          # Calculate evaluation metrics. \n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "                return {\"eval_accuracy\": accuracy}\n",
    "\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                loss=loss,\n",
    "                train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            (predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "            predictions = {'probabilities': log_probs, 'labels': predicted_labels}\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "        # Return the actual model function in the closure\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/y7/ggkv4d0s66sb_d533y_dgl6m0000gn/T/tmpx10w49rc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0327 22:45:16.536961 4711937472 estimator.py:1760] Using temporary folder as model directory: /var/folders/y7/ggkv4d0s66sb_d533y_dgl6m0000gn/T/tmpx10w49rc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/y7/ggkv4d0s66sb_d533y_dgl6m0000gn/T/tmpx10w49rc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1413f4da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:45:16.538812 4711937472 estimator.py:201] Using config: {'_model_dir': '/var/folders/y7/ggkv4d0s66sb_d533y_dgl6m0000gn/T/tmpx10w49rc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1413f4da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:45:16.843706 4711937472 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:45:19.439677 4711937472 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:45:25.462770 4711937472 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:45:25.465264 4711937472 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:45:28.734106 4711937472 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:45:32.609914 4711937472 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:45:32.825582 4711937472 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/y7/ggkv4d0s66sb_d533y_dgl6m0000gn/T/tmpx10w49rc/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:45:39.862158 4711937472 basic_session_run_hooks.py:594] Saving checkpoints for 0 into /var/folders/y7/ggkv4d0s66sb_d533y_dgl6m0000gn/T/tmpx10w49rc/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.6797863, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0327 22:45:56.952554 4711937472 basic_session_run_hooks.py:249] loss = 1.6797863, step = 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-62d4dbd55499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Beginning Training!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training took time \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "# Warmup is a period of time where the learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig()\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})\n",
    "\n",
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 21:48:23.537125 4476413376 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 21:48:26.342192 4476413376 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 21:48:32.306682 4476413376 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-03-21T01:48:32Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 21:48:32.324270 4476413376 evaluation.py:257] Starting evaluation at 2019-03-21T01:48:32Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 21:48:33.355464 4476413376 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rohan/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0320 21:48:33.357040 4476413376 deprecation.py:323] From /Users/rohan/anaconda3/envs/GradSchool/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/y7/ggkv4d0s66sb_d533y_dgl6m0000gn/T/tmpuxmqexus/model.ckpt-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 21:48:33.358529 4476413376 saver.py:1270] Restoring parameters from /var/folders/y7/ggkv4d0s66sb_d533y_dgl6m0000gn/T/tmpuxmqexus/model.ckpt-0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 21:48:35.461864 4476413376 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 21:48:35.671769 4476413376 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-03-21-01:51:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 21:51:34.732543 4476413376 evaluation.py:277] Finished evaluation at 2019-03-21-01:51:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 0: eval_accuracy = 0.15580986, global_step = 0, loss = 1.3047361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 21:51:34.733775 4476413376 estimator.py:1979] Saving dict for global step 0: eval_accuracy = 0.15580986, global_step = 0, loss = 1.3047361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 0: /var/folders/y7/ggkv4d0s66sb_d533y_dgl6m0000gn/T/tmpuxmqexus/model.ckpt-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 21:51:36.768786 4476413376 estimator.py:2039] Saving 'checkpoint_path' summary for global step 0: /var/folders/y7/ggkv4d0s66sb_d533y_dgl6m0000gn/T/tmpuxmqexus/model.ckpt-0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.15580986, 'loss': 1.3047361, 'global_step': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "\n",
    "estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
